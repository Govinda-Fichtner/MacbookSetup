# MacbookSetup Project - Cursor Rules

## ğŸ¯ Core Development Philosophy
**Minimal Complexity Principle**: Always seek the least amount of code and complexity to achieve the goal.

## ğŸ“‹ Change Implementation Methodology

### 1. **Step-by-Step Validation Protocol**
- Make ONE small change at a time
- Run `zsh -n setup.sh` and `zsh -n verify_setup.sh` after each change
- Test execution with safe commands before proceeding
- Never make multiple unrelated changes in one step

### 2. **Pattern Reuse Strategy**
- ALWAYS look for existing patterns before creating new ones
- Reuse tree structure patterns from `generate_completion_files`
- Maintain consistency between `setup.sh` and `verify_setup.sh`
- Extend existing functions rather than creating new ones

### 3. **Testing Pipeline (Required Before Commit)**
```bash
# Required checks in this exact order:
1. zsh -n setup.sh && zsh -n verify_setup.sh
2. ./verify_setup.sh > /dev/null  # execution test
3. pre-commit run --all-files
4. git add . && git commit -m "descriptive message"
5. git push origin main
```

### 4. **Visual Consistency Rules**
- Use tree structure (`â”œâ”€â”€`, `â””â”€â”€`) for hierarchical output
- Maintain color coding: `$GREEN` for success, `$YELLOW` for warnings, `$BLUE` for info
- Group related operations under section headers: `=== Section Name ===`
- Keep consistent indentation patterns across both scripts

## ğŸ”§ Code Modification Guidelines

### **Output Formatting Standards**
```bash
# Section headers
echo -e "\n=== Section Name ==="

# Tree items
printf "â”œâ”€â”€ %bOperation%b description\n" "$BLUE" "$NC"
printf "â””â”€â”€ %b[SUCCESS]%b Operation completed\n" "$GREEN" "$NC"

# Nested items
printf "â”‚   â””â”€â”€ %b[SUCCESS]%b Sub-operation ready\n" "$GREEN" "$NC"
printf "    â””â”€â”€ %b[SUCCESS]%b Deeply nested item\n" "$GREEN" "$NC"
```

### **Error Handling Preservation**
- Never remove existing error handling while making cosmetic changes
- Preserve all `|| return 1` and `|| exit 1` patterns
- Maintain graceful degradation for CI environments
- Keep warning messages for non-critical failures

### **Function Modification Rules**
- Prefer modifying output statements over changing function logic
- Use `printf` over `echo` for colored output with variables
- Replace `log_info` with section headers only for major groupings
- Keep `log_error` and `log_warning` for actual error conditions

## ğŸ“ Commit Message Standards

### **Format**: `<type>: <description> - <details>`

**Types**: `feat`, `fix`, `refactor`, `style`, `docs`, `test`, `chore`

**Example**:
```
feat: add tree structure to setup.sh output for consistency
- Apply hierarchical tree output to match verify_setup.sh visual style
- Group operations under sections: Installing Packages, Language Environments
- Use minimal code changes, reusing existing tree patterns
- Maintain clean visual flow throughout setup process
```

## ğŸ”§ Shell Completion Update Requirement

### **Mandatory Completion Check**
When modifying any shell script (*.sh files), you MUST check if shell completion needs updates:

1. **Check completion file**: `_mcp_manager` for mcp_manager.sh changes
2. **Verify commands match**: Ensure completion options match actual commands
3. **Test completion**: Verify tab completion works for new/modified commands
4. **Update if needed**: Add new commands, options, or server IDs to completion

### **Files to Check**:
- `_mcp_manager` - Completion for mcp_manager.sh
- Any other completion files in the project

### **Testing**:
```bash
# Source completion and test
source _mcp_manager
./mcp_manager.sh <TAB><TAB>  # Should show available commands
```

## ğŸš« Anti-Patterns to Avoid

### **Complexity Anti-Patterns**
- âŒ Creating new utility functions when existing ones work
- âŒ Adding configuration files for simple formatting changes
- âŒ Over-engineering solutions that could be simple printf statements
- âŒ Breaking working functionality for cosmetic improvements

### **Testing Anti-Patterns**
- âŒ Making multiple changes without intermediate testing
- âŒ Committing without running the full testing pipeline
- âŒ Assuming syntax check means execution will work
- âŒ Skipping pre-commit hooks "just this once"

### **Security Anti-Patterns**
- âŒ **NEVER commit `.envrc` files** - They contain sensitive environment variables
- âŒ Committing any file with real API tokens, passwords, or secrets
- âŒ Using real credentials in example files (use placeholders like "your-token-here")
- âŒ Ignoring GitHub push protection warnings about detected secrets

## ğŸ¨ Project-Specific Patterns

### **Shell Script Consistency**
- Both `setup.sh` and `verify_setup.sh` should have matching visual output
- Use shared color variables: `$RED`, `$GREEN`, `$BLUE`, `$YELLOW`, `$NC`
- Extract version numbers using the shared `extract_version()` function
- Handle missing files gracefully with warnings, not errors

### **CI/Local Environment Handling**
- Always check `[[ "${CI:-false}" == "true" ]]` for CI-specific behavior
- Use `SKIP_ORBSTACK=true` for testing without Docker dependencies
- Provide graceful fallbacks for missing dependencies in CI

### **Zsh Compatibility**
- Use `for item in "${array[@]}"` instead of bash-style `${!array[@]}`
- Test all changes with `zsh -n` syntax checking
- Ensure compatibility with both zsh and bash environments

## ğŸ› ï¸ Tool Integration Patterns (Added from Node.js/nvm experience)

### **Tool Classification and Handling**
- **Standard CLI Tools**: rbenv, pyenv, terraform â†’ Direct command line access
- **Sourced Tools**: nvm â†’ Require shell sourcing for initialization
- **GUI Applications**: Warp, iTerm2 â†’ Configuration via plist manipulation
- **Container Tools**: Docker, OrbStack â†’ Environment-dependent availability

### **Language Environment Standards**
```bash
# Template for adding new language environments:
setup_<language>_environment() {
  printf "â”œâ”€â”€ %b<Language> Environment%b\n" "$BLUE" "$NC"

  # 1. Validate tool availability (with proper sourcing if needed)
  # 2. Determine latest version using tool-specific method
  # 3. Check if version already installed (tool-specific detection)
  # 4. Background installation with progress spinner
  # 5. Set default/global version
  # 6. Optional: Update package manager
  # 7. Success confirmation
}
```

### **Verification Complexity Handling**
- **Standard Tools**: Use `check_command "$tool"` and `"$tool" --version`
- **Sourced Tools**: Create special case blocks with proper initialization
- **Version Extraction**: Add tool-specific patterns to `extract_version()` function
- **Environment Graceful Degradation**: Distinguish between missing vs unavailable in CI

### **Shell Integration Rules**
- Tools requiring sourcing (like nvm) need:
  - Initialization in setup functions: `source "$(brew --prefix)/opt/tool/tool.sh"`
  - Special verification logic: Custom detection blocks in verify_setup.sh
  - Shell config addition: Proper PATH and sourcing in .zshrc
  - Completion handling: Both shell integration AND completion files

### **Error Handling for Special Cases**
- Use tool-specific error detection rather than generic patterns
- Provide informative error messages about tool requirements
- Maintain CI compatibility with appropriate warnings vs errors
- Always test both "tool not installed" and "tool installed but not working" scenarios

### **Consistency Enforcement Rules**
- Language environments must follow identical tree structure patterns
- All background installations must use `show_progress()` with proper spinner
- Version extraction must use shared `extract_version()` function
- Verification logic must handle tool-specific requirements while maintaining output consistency

## ğŸ”— MCP Server Integration Patterns (Added from GitHub/CircleCI experience)

### **MCP Server Addition Protocol**
When adding new MCP servers to the project, follow this exact pattern:

```bash
# 1. Add server to AVAILABLE_SERVERS array in mcp_manager.sh
AVAILABLE_SERVERS=("github" "circleci" "new-server")

# 2. Add Docker image mapping in get_docker_image()
get_docker_image() {
  case "$1" in
    "github") echo "mcp/github-mcp-server:latest" ;;
    "circleci") echo "local/mcp-server-circleci:latest" ;;
    "new-server") echo "vendor/new-server:latest" ;;
    *) return 1 ;;
  esac
}

# 3. Add environment variables in get_expected_env_vars()
get_expected_env_vars() {
  case "$1" in
    "new-server")
      echo "NEW_SERVER_TOKEN NEW_SERVER_API_KEY NEW_SERVER_BASE_URL"
      ;;
  esac
}

# 4. Add placeholder mapping in get_env_placeholder()
get_env_placeholder() {
  case "$1" in
    "NEW_SERVER_TOKEN") echo "your_new_server_token_here" ;;
    "NEW_SERVER_API_KEY") echo "your_api_key_here" ;;
    "NEW_SERVER_BASE_URL") echo "https://api.newserver.com" ;;
  esac
}
```

### **Configuration Generation Standards**
- **ALWAYS use --env-file approach**: Never inline environment variables in JSON
- **Use absolute paths**: `--env-file /Users/gfichtner/MacbookSetup/.env`
- **Generate .env_example**: Never overwrite existing `.env` files
- **Include all available servers**: Use `get_available_servers()` not just working ones
- **Maintain JSON structure consistency**: Both Cursor and Claude Desktop formats

### **Environment File Safety Rules**
- âŒ **NEVER generate or overwrite .env files directly**
- âœ… **ALWAYS generate .env_example with placeholders**
- âœ… **Read tokens from .env file, not environment variables**
- âœ… **Validate against placeholders**: Detect "your_token_here" patterns
- âœ… **Preserve existing .env**: Show "[INFO] Existing .env file found (keeping as-is)"

### **Token Detection and Validation**
```bash
# Template for server token validation:
server_has_real_tokens() {
  local server="$1"
  local env_vars
  env_vars=$(get_expected_env_vars "$server")

  for var in $env_vars; do
    local value placeholder
    value=$(grep "^${var}=" .env 2>/dev/null | cut -d'=' -f2- | tr -d '"')
    placeholder=$(get_env_placeholder "$var")

    if [[ -z "$value" || "$value" == "$placeholder" ]]; then
      return 1
    fi
  done
  return 0
}
```

### **Container Environment Testing**
- **Test variables inside containers**: Use `docker run --env-file .env image sh -c "echo \$VAR"`
- **Validate environment visibility**: Ensure all expected variables are accessible
- **Handle mixed output gracefully**: Use `grep -o` to extract JSON from startup messages
- **Support different parse modes**: Handle both "json" and default parsing

### **Debug Output Prevention (CRITICAL)**
- âŒ **NEVER leave debug trace enabled**: Check for `set -x`, `functrace`, etc.
- âŒ **NEVER output variable assignments**: Avoid `container_value=`, `image=` patterns
- âœ… **Use structured output**: Tree format with proper status indicators
- âœ… **Redirect debug info**: Send debugging to stderr or suppress entirely
- âœ… **Test JSON validity**: Always validate with `jq` before committing

### **Health Check Architecture**
- **Basic Protocol Tests**: Always work in CI (no authentication required)
- **Advanced Functionality Tests**: Only when real tokens detected
- **Graceful Degradation**: Warn about missing tokens, don't fail
- **Container Environment Verification**: Test actual Docker variable visibility
- **Mixed Output Handling**: Support servers with startup messages before JSON

### **Testing Requirements for New Servers**
When adding MCP servers, update `spec/mcp_manager_spec.sh`:

```bash
# 1. Update expected_servers in has_expected_servers()
local expected_servers="github circleci new-server"

# 2. Add environment variable tests
The output should include "NEW_SERVER_TOKEN"
The output should include "NEW_SERVER_API_KEY"

# 3. Add placeholder tests
The output should include "your_new_server_token_here"

# 4. Add Docker image tests
The output should include "vendor/new-server:latest"
```

### **JSON Structure Consistency**
- **Cursor Format**: Direct server mapping `{ "server": { "command": "docker", "args": [...] } }`
- **Claude Desktop Format**: Nested under mcpServers `{ "mcpServers": { "server": {...} } }`
- **Args Array Standard**: `["run", "--rm", "-i", "--env-file", "path", "image"]`
- **No Inline Environment Variables**: Configuration should be environment-agnostic

### **Error Handling for MCP Servers**
- **Missing Docker**: Graceful fallback, generate configs anyway
- **Missing Tokens**: Warning messages, not errors
- **Container Failures**: Detailed error output with full Docker response
- **JSON Parsing Errors**: Strip non-JSON content before parsing
- **File Permission Issues**: Clear error messages about config file locations

### **Shell Completion Extension**
When adding new MCP servers, update `_mcp_manager`:
```bash
# Add server names to completion
case $line[1] in
  test|health|config-write)
    _arguments '*:servers:(github circleci new-server)'
    ;;
esac
```

## ğŸ“– Documentation Maintenance Requirements

### **README.md Update Mandate**
When making significant changes to the project, you MUST update the README.md file to reflect:

**Required Updates For:**
- **New features or tools**: Add to appropriate sections, update examples
- **Script behavior changes**: Update testing strategy, CI behavior descriptions
- **Error handling improvements**: Update troubleshooting section
- **Configuration changes**: Update MCP server documentation, environment setup
- **Testing methodology changes**: Update CI testing strategy section
- **Output format changes**: Update examples and expected behavior

**Documentation Standards:**
- âœ… **Update examples** to reflect actual current behavior
- âœ… **Maintain consistency** between code behavior and documentation
- âœ… **Add new troubleshooting entries** for newly discovered issues
- âœ… **Update version numbers** and tool lists when dependencies change
- âœ… **Validate all links** and commands in documentation still work

**Process:**
1. Make code changes
2. Test functionality
3. Update README.md accordingly
4. Commit both code AND documentation changes together

**âŒ Anti-Pattern**: Never commit significant functionality changes without corresponding README updates

## ğŸ§ª Test-Driven Development (TDD) & Behavior-Driven Development (BDD) Principles

### **TDD Methodology (Red-Green-Refactor)**
**MANDATORY**: All new features MUST follow TDD cycle:

1. **ğŸ”´ RED**: Write failing tests first
2. **ğŸŸ¢ GREEN**: Write minimal code to make tests pass
3. **ğŸ”µ REFACTOR**: Improve code while keeping tests green

### **Test-First Development Rules**
- âŒ **NEVER write production code without a failing test first**
- âœ… **ALWAYS start with the test that describes the expected behavior**
- âœ… **Write the smallest possible test that fails**
- âœ… **Only write enough production code to make the test pass**

### **ShellSpec Testing Standards**

#### **Test Organization**
```bash
# File structure for tests
spec/
â”œâ”€â”€ spec_helper.sh          # Shared test utilities
â”œâ”€â”€ mcp_manager_spec.sh     # Core MCP manager functionality
â”œâ”€â”€ mcp_inspector_spec.sh   # New: Inspector functionality tests
â””â”€â”€ integration_spec.sh     # End-to-end integration tests
```

#### **Test Writing Patterns**
```bash
# Use descriptive test names that explain behavior
Describe 'mcp_manager.sh inspect command'
  Describe 'when inspecting all servers'
    Context 'with no running containers'
      It 'should display "No MCP servers currently running"'
        When run ./mcp_manager.sh inspect
        The output should include "No MCP servers currently running"
        The status should be success
      End
    End

    Context 'with running containers'
      BeforeEach 'start_test_containers'
      AfterEach 'cleanup_test_containers'

      It 'should discover and list running servers'
        When run ./mcp_manager.sh inspect
        The output should include "Running MCP servers"
        The output should include "github"
        The status should be success
      End
    End
  End
End
```

#### **Test Categories by Scope**
1. **Unit Tests**: Test individual functions in isolation
2. **Integration Tests**: Test component interactions
3. **System Tests**: Test complete workflows end-to-end
4. **CI Tests**: Tests that run in CI environment (no Docker dependencies)

### **BDD Behavior Specification**

#### **Feature Definition Template**
```bash
# Every new feature starts with behavior specification
Describe 'MCP Inspector Feature'
  Describe 'inspect command basic functionality'
    It 'should show help when no arguments provided'
    It 'should discover running MCP server containers'
    It 'should validate environment variables'
    It 'should test server connectivity'
  End

  Describe 'inspect command advanced features'
    It 'should launch web UI on --ui flag'
    It 'should validate client configurations'
    It 'should run in CI-friendly mode'
    It 'should debug specific servers with --debug'
  End
End
```

#### **Given-When-Then Structure**
```bash
# Use Context/Setup for Given, When for actions, assertions for Then
Context 'Given a configured MCP server environment'
  Setup 'configure_test_environment'

  It 'When inspecting a specific server, Then should show detailed information'
    When run ./mcp_manager.sh inspect github
    The output should include "=== MCP Server Inspection: github ==="
    The output should include "[SERVER] GitHub MCP Server"
    The status should be success
  End
End
```

### **Test Implementation Workflow**

#### **For New Features (Inspector Example)**
```bash
# 1. Define the behavior first (RED)
It 'should provide UI access to MCP inspector'
  When run ./mcp_manager.sh inspect --ui
  The output should include "Inspector UI started"
  The output should include "http://localhost:6274"
  The status should be success
End

# 2. Run test (should fail)
shellspec spec/mcp_inspector_spec.sh

# 3. Implement minimal code to pass (GREEN)
# Add basic --ui handling to handle_inspect_command()

# 4. Run test (should pass)
shellspec spec/mcp_inspector_spec.sh

# 5. Refactor and improve (REFACTOR)
# Enhance error handling, improve output format
```

#### **Test Environment Setup Standards**
```bash
# Use consistent test helper patterns
setup_test_environment() {
  export TEST_HOME="$PWD/test_home"
  export CI=false
  mkdir -p "$TEST_HOME/.cursor"
  mkdir -p "$TEST_HOME/Library/Application Support/Claude"
}

cleanup_test_environment() {
  rm -rf "$TEST_HOME"
  docker container prune -f 2>/dev/null || true
}

mock_docker_commands() {
  # Create mock functions for Docker in test environment
  docker() {
    case "$1" in
      "ps") echo "CONTAINER ID   IMAGE                     NAMES"
            echo "123abc         mcp/github:latest        test-github" ;;
      "images") echo "mcp/github   latest   123   2 hours ago   100MB" ;;
    esac
  }
}
```

### **Test Coverage Requirements**

#### **Mandatory Test Coverage**
- âœ… **All new commands must have tests**
- âœ… **All error conditions must be tested**
- âœ… **Both CI and local environments must be tested**
- âœ… **Edge cases and error handling must be covered**

#### **Test Scenarios Matrix**
```bash
# Every new feature needs tests for:
#
# Environment Matrix:
# - Local development (Docker available)
# - CI environment (CI=true, limited Docker)
# - Missing dependencies (no Docker, no tools)
#
# Input Matrix:
# - Valid inputs
# - Invalid inputs
# - Missing inputs
# - Edge case inputs
#
# State Matrix:
# - Clean environment
# - Existing configurations
# - Partially configured state
# - Error states
```

### **Test Quality Standards**

#### **Test Readability Rules**
- âœ… **Test names should read like documentation**
- âœ… **Use descriptive Context and Describe blocks**
- âœ… **One assertion per test when possible**
- âœ… **Setup and teardown should be clear and isolated**

#### **Test Reliability Rules**
- âœ… **Tests must be deterministic (no flaky tests)**
- âœ… **Tests must be isolated (no dependencies between tests)**
- âœ… **Tests must clean up after themselves**
- âœ… **Tests must work in both CI and local environments**

### **Debugging Test Failures**

#### **Test Debugging Commands**
```bash
# Run specific test with verbose output
shellspec --format documentation spec/mcp_inspector_spec.sh

# Run single test case
shellspec --example "should discover running servers" spec/mcp_inspector_spec.sh

# Debug test with trace
shellspec --trace spec/mcp_inspector_spec.sh
```

#### **Common Test Failure Patterns**
- **Environment not isolated**: Tests affecting each other
- **Missing mocks**: Tests failing due to external dependencies
- **Race conditions**: Tests depending on timing
- **Path issues**: Tests not finding required files

### **Test-Driven Refactoring**

#### **Safe Refactoring Process**
1. âœ… **Ensure all tests pass before refactoring**
2. âœ… **Add tests for edge cases if missing**
3. âœ… **Refactor incrementally**
4. âœ… **Run tests after each small change**
5. âœ… **Never skip tests because "it's just refactoring"**

### **TDD Anti-Patterns to Avoid**

#### **Development Anti-Patterns**
- âŒ **Writing production code before writing tests**
- âŒ **Writing tests that always pass (testing implementation, not behavior)**
- âŒ **Skipping the RED phase (not seeing tests fail first)**
- âŒ **Making multiple changes before running tests**

#### **Test Anti-Patterns**
- âŒ **Tests that depend on external services**
- âŒ **Tests that require manual setup**
- âŒ **Tests that test implementation details instead of behavior**
- âŒ **Giant tests that test multiple behaviors**

### **Integration with Existing Workflow**

#### **Updated Testing Pipeline**
```bash
# Enhanced testing pipeline for TDD workflow:
1. Write failing test first
2. zsh -n setup.sh && zsh -n verify_setup.sh  # Syntax check
3. shellspec spec/                            # Run all tests
4. Write minimal code to pass the test
5. shellspec spec/                            # Verify test passes
6. ./verify_setup.sh > /dev/null              # Integration test
7. pre-commit run --all-files                 # Code quality
8. git add . && git commit -m "descriptive message"
9. git push origin main
```

#### **CI Integration**
- âœ… **All tests must pass in CI environment**
- âœ… **Tests should gracefully handle CI limitations (no Docker)**
- âœ… **Test results should be clearly reported**
- âœ… **Failed tests should provide actionable error messages**

## ğŸ›¡ï¸ Major Change Approval Protocol

### **When to Require User Confirmation**
Any change that falls into these categories **MUST** get explicit user approval before implementation:

#### **Structural Changes**
- âŒ **NEVER** reorganize directory structure without approval
- âŒ **NEVER** move files to new locations without confirmation
- âŒ **NEVER** delete files or directories (even temp files) without asking
- âŒ **NEVER** rename core scripts or configuration files

#### **Destructive Operations**
- âŒ **NEVER** use `rm`, `mv`, or `git rm` commands without explicit permission
- âŒ **ALWAYS** use `rm -f` or `rm -rf` to avoid interactive prompts when removal is approved
- âŒ **NEVER** remove or modify existing documentation sections
- âŒ **NEVER** change established workflows or testing pipelines
- âŒ **NEVER** modify configuration files that affect user environment

#### **Required Approval Process**
When a major change is needed:

1. **ğŸ›‘ STOP and present proposal**: "I recommend the following changes: [detailed list]"
2. **ğŸ“‹ Explain rationale**: Why these changes are needed and what benefits they provide
3. **âš ï¸ Highlight risks**: What could go wrong or what will be affected
4. **ğŸ¤” Wait for approval**: "Do you approve this approach?" or "Would you prefer a different solution?"
5. **âœ… Only proceed after explicit confirmation**: User says "yes," "proceed," or "approved"

#### **Example Proposal Format**
```
## ğŸ“‹ PROPOSAL: Directory Restructure

**Problem**: Supporting files are cluttering the root directory

**Proposed Changes**:
- Create support/ directory structure
- Move Dockerfile.mcp-inspector â†’ support/docker/mcp-inspector/
- Move _mcp_manager â†’ support/completions/
- Remove outdated .envrc_example

**Benefits**: Cleaner root, better organization, scalable for future MCP servers

**Risks**: Need to update references in scripts, potential disruption

**Question**: Do you approve this directory restructure approach?
```

### **Minor Changes That Don't Need Approval**
- âœ… Bug fixes in existing functionality
- âœ… Code formatting and style improvements
- âœ… Adding tests for existing features
- âœ… Documentation clarifications and corrections
- âœ… Performance optimizations that don't change behavior

### **When in Doubt**
- **Always err on the side of asking for permission**
- **Present proposals before implementation**
- **Respect the user's project ownership**
- **Remember: it's easier to get approval than to fix mistakes**

## ğŸ”„ Continuous Improvement
- Document successful patterns in this file
- Update rules based on what works in practice
- Keep the "minimal complexity" principle as the north star
- Review and refine these rules after major changes
- **Always maintain README.md alongside code changes**
- **Continuously improve test coverage and quality**
- **Refactor tests alongside production code**
